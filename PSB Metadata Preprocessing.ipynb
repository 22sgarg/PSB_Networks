{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cb7669",
   "metadata": {},
   "source": [
    "## Scraping Titles and Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310419a5",
   "metadata": {},
   "source": [
    "Scraped Titles and Authors for 1999 to 2024 (Used existing scraped files for 1996 and 1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1309c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5d4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(csv_file, year):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if year == 1996:\n",
    "        if 'Title' in df.columns and ('Author' in df.columns):\n",
    "            result_dict = {row['Title']: (row['Author'], year) for index, row in df.iterrows()}\n",
    "            return result_dict\n",
    "        else:\n",
    "            raise ValueError(\"CSV file must contain 'title', 'author', and 'year' columns\")\n",
    "    elif year == 1997:\n",
    "        if 'Title' in df.columns and ('Authors' in df.columns):\n",
    "            result_dict = {row['Title']: (row['Authors'], year) for index, row in df.iterrows()}\n",
    "            return result_dict\n",
    "        else:\n",
    "            raise ValueError(\"CSV file must contain 'title', 'author', and 'year' columns\")\n",
    "    else:\n",
    "        raise ValueError(\"year must be 1996 or 1997\")\n",
    "\n",
    "paper_meta = csv_to_dict('1996.csv',1996)\n",
    "paper_meta.update(csv_to_dict('1997.csv',1997))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ce817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clean_author(author_text):\n",
    "    author_text = re.sub(r'\\s+', ' ', author_text)  # Replace multiple spaces with a single space\n",
    "    author_text = author_text.replace('\\n', ' ')  # Replace newlines with a space\n",
    "    return author_text\n",
    "\n",
    "def clean_title(title):\n",
    "    # Remove excess whitespace and line breaks\n",
    "    title = re.sub(r'\\s+', ' ', title)  # Replace multiple spaces with a single space\n",
    "    title = title.replace('\\n', ' ')  # Replace newlines with a space\n",
    "    title = title.strip()  # Remove leading/trailing whitespace\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f363f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(html, year, entries):\n",
    "    if not html:\n",
    "        return {}\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = soup.find_all(['p', 'dt', 'h3'])\n",
    "    \n",
    "    skip_section = False\n",
    "\n",
    "    for tag in tags:\n",
    "        if tag.name == 'h3':\n",
    "            if 'workshops' in tag.text.lower():\n",
    "                skip_section = True\n",
    "                continue  # Skip the workshops section header itself\n",
    "        \n",
    "        if skip_section:\n",
    "            continue  # Skip all tags when in the Workshops section\n",
    "        \n",
    "        if tag.name in ['p', 'dt']:\n",
    "            a_tag = tag.find('a', href=lambda href: href and href.lower().endswith('.pdf'))\n",
    "            if a_tag:\n",
    "                title = clean_title(a_tag.text.strip())\n",
    "                if title not in [\"Preface\", \"Session Introduction\", \"Introduction\"] and not title.endswith(\"introduction\"):\n",
    "                    author_tag = tag.find('i') or tag.find('b') if tag.name == 'p' else tag.find_next_sibling('dd')\n",
    "                    if author_tag:\n",
    "                        author_text = author_tag.text.strip().split(';')[0]\n",
    "                        if title not in entries:\n",
    "                            entries[title] = (clean_author(author_text), year)\n",
    "                    \n",
    "    return entries\n",
    "\n",
    "def extract_data_2002(html, year, entries):\n",
    "    if not html:\n",
    "        return {}\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find all dt and dd tags\n",
    "    dt_tags = soup.find_all('dt')\n",
    "    dd_tags = soup.find_all('dd')\n",
    "\n",
    "    for dt, dd in zip(dt_tags, dd_tags):\n",
    "        # Get the title, which is the text of the a tag within dt\n",
    "        title_tag = dt.find('a')\n",
    "        title = clean_title(title_tag.text.strip())\n",
    "        if title != \"Session Introduction\":\n",
    "            # Get the authors, which is the text of the i tag within dd\n",
    "            authors_tag = dd.find('i')\n",
    "            if authors_tag:\n",
    "                author_text = authors_tag.text.strip().split(';')[0]\n",
    "                authors = authors_tag.text.strip()\n",
    "                entries[title] = (clean_author(author_text), year)\n",
    "                    \n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefadada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_titles_authors_years(start_year, end_year):\n",
    "    base_url = \"http://psb.stanford.edu/psb-online/proceedings/psb\"\n",
    "    titles_authors_years = {}\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        year_suffix = str(year)[-2:]\n",
    "        url = f\"{base_url}{year_suffix}/\"\n",
    "        html_content = fetch_html(url)\n",
    "        if year == 2002:\n",
    "            data = extract_data_2002(html_content, year, titles_authors_years)\n",
    "        else:\n",
    "            data = extract_data(html_content, year, titles_authors_years)\n",
    "\n",
    "    return titles_authors_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887e064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Predicting Longitudinal Outcomes of Alzheimer's Disease via a Tensor-Based Joint Classification and Regression Model, First Author: Lodewijk Brand, Kai Nichols, Hua Wang, Heng Huang, Li Shen, for the ADNI, Year: 2020\n",
      "Title: Robustly Extracting Medical Knowledge from EHRs: A Case Study of Learning a Health Knowledge Graph, First Author: Irene Y. Chen, Monica Agrawal, Steven Horng, David Sontag, Year: 2020\n",
      "Title: Increasing Clinical Trial Accrual via Automated Matching of Biomarker Criteria, First Author: Jessica W. Chen, Christian A. Kunder, Nam Bui, James L. Zehnder, Helio A. Costa, Henning Stehr, Year: 2020\n",
      "Title: Addressing the Credit Assignment Problem in Treatment Outcome Prediction Using Temporal Difference Learning, First Author: Sahar Harati, Andrea Crowell, Helen Mayberg, Shamim Nema, Year: 2020\n",
      "Title: Multiclass Disease Classification from Microbial Whole-Community Metagenomes, First Author: Saad Khan, Libusha Kelly, Year: 2020\n",
      "Title: LitGen: Genetic Literature Recommendation Guided by Human Explanations, First Author: Allen Nie, Arturo L. Pineda, Matt W. Wright, Hannah Wand, Bryan Wulf, Helio A. Costa, Ronak Y. Patel, Carlos D. Bustamante, James Zou, Year: 2020\n",
      "Title: From Genome to Phenome: Predicting Multiple Cancer Phenotypes Based on Somatic Genomic Alterations via the Genomic Impact Transformer, First Author: Yifeng Tao, Chunhui Cai, William W. Cohen, Xinghua Lu, Year: 2020\n",
      "Title: Automated Phenotyping of Patients with Non-Alcoholic Fatty Liver Disease Reveals Clinically Relevant Disease Subtypes, First Author: Maxence Vandromme, Tomi Jun, Ponni Perumalswami, Joel T. Dudley, Andrea Branch, Li Li, Year: 2020\n",
      "Title: Monitoring ICU Mortality Risk with a Long Short-Term Memory Recurrent Neural Network, First Author: Ke Yu, Mingda Zhang, Tianyi Cui, Milos Hauskrecht, Year: 2020\n",
      "Title: Multilevel Self-Attention Model and Its Use on Medical Risk Prediction, First Author: Xianlong Zeng, Yunyi Feng, Soheil Moosavinasab, Deborah Lin, Simon Lin, Chang Liu, Year: 2020\n",
      "Title: Identifying Transitional High Cost Users from Unstructured Patient Profiles Written by Primary Care Physicians, First Author: Haoran Zhang, Elisa Candido, Andrew S. Wilton, Raquel Duchen, Liisa Jaakkimainen, Walter Wodchis, Quaid Morris, Year: 2020\n",
      "Title: Obtaining Dual-Energy Computed Tomography (CT) Information from a Single-Energy CT Image for Quantitative Imaging Analysis of Living Subjects by Using Deep Learning, First Author: Wei Zhao, Tianling Lv, Rena Lee, Yang Chen, Lei Xing, Year: 2020\n",
      "Title: Many-to-One Binding by Intrinsically Disordered Protein Regions, First Author: Wei-Lun Alterovitz, Eshel Faraggi, Christopher J. Oldfield, Jingwei Meng, Bin Xue, Fei Huang, Pedro Romero, Andrzej Kloczkowski, Vladimir N. Uversky, A. Keith Dunker, Year: 2020\n",
      "Title: Disordered Function Conjunction: On the In-Silico Function Annotation of Intrinsically Disordered Regions, First Author: Sina Ghadermarzi, Akila Katuwawala, Christopher J. Oldfield, Amita Barik, Lukasz Kurgan, Year: 2020\n",
      "Title: De novo Ensemble Modeling Suggests that AP2-Binding to Disordered Regions Can Increase Steric Volume of Epsin but Not Eps15, First Author: N. Suhas Jagannathan, Christopher W. V. Hogue, Lisa Tucker-Kellogg, Year: 2020\n",
      "Title: Modulation of p53 Transactivation Domain Conformations by Ligand Binding and Cancer-Associated Mutations, First Author: Xiaorong Liu, Jianhan Chen, Year: 2020\n",
      "Title: Exploring Relationships Between the Density of Charged Tracts Within Disordered Regions and Phase Separation, First Author: Ramiz Somjee, Diana M. Mitrea, Richard W. Kriwacki, Year: 2020\n",
      "Title: PhySigs: Phylogenetic Inference of Mutational Signature Dynamics, First Author: Sarah Christensen, Mark D.M. Leiserson, Mohammed El-Kebir, Year: 2020\n",
      "Title: TrackSigFreq: Subclonal Reconstructions Based on Mutation Signatures and Allele Frequencies, First Author: Caitlin F Harrigan, Yulia Rubanova, Quaid Morris, Alina Selega, Year: 2020\n",
      "Title: Impact of Mutational Signatures on microRNA and Their Response Elements, First Author: Eirini Stamoulakatou, Pietro Pinoli, Stefano Ceri, Rosario Piro, Year: 2020\n",
      "Title: DNA Repair Footprint Uncovers Contribution of DNA Repair Mechanism to Mutational Signatures, First Author: Damian Wojtowicz, Mark D.M. Leiserson, Roded Sharan, Teresa M. Przytycka, Year: 2020\n",
      "Title: Genome Gerrymandering: Optimal Division of the Genome into Regions with Cancer Type Specific Differences in Mutation Rates, First Author: Adamo Young, Jacob Chmura, Yoonsik Park, Quaid Morris, Gurnit Atwal, Year: 2020\n",
      "Title: Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data, First Author: Andrew L. Beam, Benjamin Kompa, Allen Schmaltz, Inbar Fried, Griffin Weber, Nathan Palmer, Xu Shi, Tianxi Cai, Isaac S. Kohane, Year: 2020\n",
      "Title: Assessment of Imputation Methods for Missing Gene Expression Data in Meta-Analysis of Distinct Cohorts of Tuberculosis Patients, First Author: Carly A. Bobak, Lauren McDonnell, Matthew D. Nemesure, Justin Lin, Jane E. Hill, Year: 2020\n",
      "Title: Towards Identifying Drug Side Effects from Social Media Using Active Learning and Crowd Sourcing, First Author: Sophie Burkhardt, Julia Siekiera, Josua Glodde, Miguel A. Andrade-Navarro, Stefan Kramer, Year: 2020\n",
      "Title: Microvascular Dynamics from 4D Microscopy Using Temporal Segmentation, First Author: Shir Gur, Lior Wolf, Lior Golgher, Pablo Blinder, Year: 2020\n",
      "Title: Using Transcriptional Signatures to Find Cancer Drivers with LURE, First Author: David Haan, Ruikang Tao, Verena Friedl, Ioannis N Anastopoulos, Christopher K Wong, Alana S Weinstein, Joshua M Stuart, Year: 2020\n",
      "Title: PAGE-Net: Interpretable and Integrative Deep Learning for Survival Analysis Using Histopathological Images and Genomic Data, First Author: Jie Hao, Sai Chandra Kosaraju, Nelson Zange Tsaku, Dae Hyun Song, Mingon Kang, Year: 2020\n",
      "Title: Machine Learning Algorithms for Simultaneous Supervised Detection of Peaks in Multiple Samples and Cell Types, First Author: Toby Dylan Hocking, Guillaume Bourque, Year: 2020\n",
      "Title: Learning a Latent Space of Highly Multidimensional Cancer Data, First Author: Benjamin Kompa, Beau Coker, Year: 2020\n",
      "Title: Scaling Structural Learning with NO-BEARS to Infer Causal Transcriptome Networks, First Author: Hao-Chih Lee, Matteo Danieletto, Riccardo Miotto, Sarah T. Cherng, and Joel T. Dudley, Year: 2020\n",
      "Title: PathFlowAI: A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology, First Author: Joshua J. Levy, Lucas A. Salas, Brock C. Christensen, Aravindhan Sriharan, Louis J. Vaickus, Year: 2020\n",
      "Title: Improving Survival Prediction Using a Novel Feature Selection and Feature Reduction Framework Based on the Integration of Clinical and Molecular Data, First Author: Lisa Neums, Richard Meier, Devin C. Koestler, Jeffrey A. Thompson, Year: 2020\n",
      "Title: Bayesian Semi-Nonnegative Matrix Tri-Factorization to Identify Pathways Associated with Cancer Phenotypes, First Author: Sunho Park, Nabhonil Kar, Jae-Ho Cheong, Tae Hyun Hwang, Year: 2020\n",
      "Title: Graph-Based Information Diffusion Method for Prioritizing Functionally Related Genes in Protein- Protein Interaction Networks, First Author: Minh Pham, Olivier Lichtarge, Year: 2020\n",
      "Title: Tree-Weighting for Multi-Study Ensemble Learners, First Author: Maya Ramchandran, Prasad Patil, Giovanni Parmigiani, Year: 2020\n",
      "Title: A Literature-Based Knowledge Graph Embedding Method for Identifying Drug Repurposing Opportunities in Rare Diseases, First Author: Daniel N. Sosa, Alexander Derry, Margaret Guo, Eric Wei, Connor Brinton, Russ B. Altman, Year: 2020\n",
      "Title: PTR Explorer: An approach to identify and explore Post Transcriptional Regulatory mechanisms using proteogenomics, First Author: Arunima Srivastava, Michael Sharpnack, Kun Huang, Parag Mallick, Raghu Machiraju Dowell, Year: 2020\n",
      "Title: Two-stage ML Classifier for Identifying Host Protein Targets of the Dengue Protease, First Author: Jacob T. Stanley, Alison R. Gilchrist, Alex C. Stabell, Mary A. Allen, Sara L. Sawyer, Robin D. Dowell, Year: 2020\n",
      "Title: Network Representation of Large-Scale Heterogeneous RNA Sequences with Integration of Diverse Multi-omics, Interactions, and Annotations Data, First Author: Nhat Tran, Jean Gao, Year: 2020\n",
      "Title: Enhancing Model Interpretability and Accuracy for Disease Progression Prediction via Phenotype-Based Patient Similarity Learning, First Author: Yue Wang, Tong Wu, Yunlong Wang, Gao Wang, Year: 2020\n",
      "Title: Hadoop and PySpark for Reproducibility and Scalability of Genomic Sequencing Studies, First Author: Nicholas R. Wheeler, Penelope Benchek, Brian W. Kunkle, Kara L. Hamilton-Nelson, Mike Warfe, Jeremy R. Fondran, Jonathan L. Haines, William S. Bush, Year: 2020\n",
      "Title: CERENKOV3: Clustering and Molecular Network-Derived Features Improve Computational Prediction of Functional Noncoding SNPs, First Author: Yao Yao, Stephen A. Ramsey, Year: 2020\n",
      "Title: Integrated Cancer Subtyping using Heterogeneous Genome-Scale Molecular Datasets, First Author: Suzan Arslanturk, Sorin Draghici, Tin Nguyen, Year: 2020\n",
      "Title: AnomiGAN: Generative Adversarial Networks for Anonymizing Private Medical Data, First Author: Ho Bae, Dahuin Jung, Hyun-Soo Choi, Sungroh Yoon, Year: 2020\n",
      "Title: Frequency of ClinVar Pathogenic Variants in Chronic Kidney Disease Patients Surveyed for Return of Research Results at a Cleveland Public Hospital, First Author: Dana C. Crawford, John Lin, Jessica N. Cooke Bailey, Tyler Kinzy, John R. Sedor, John F. O'Toole, Williams S. Bush, Year: 2020\n",
      "Title: Assessment of Coverage for Endogenous Metabolites and Exogenous Chemical Compounds Using an Untargeted Metabolomics Platform, First Author: Sek Won Kong, Carles Hernandez-Ferrer, Year: 2020\n",
      "Title: Coverage Profile Correction of Shallow-Depth Circulating Cell-Free DNA Sequencing via Multi- Distance Learning, First Author: Nicholas B. Larson, Melissa C. Larson, Jie Na, Carlos P. Sosa, Chen Wang, Jean-Pierre Kocher, Ross Rowsey, Year: 2020\n",
      "Title: PGxMine: Text Mining for Curation of PharmGKB, First Author: Jake Lever, Julia M. Barbarino, Li Gong, Rachel Huddart, Katrin Sangkuhl, Ryan Whaley, Michelle Whirl-Carrillo, Mark Woon, Teri E. Klein and Russ B. Altman, Year: 2020\n",
      "Title: Network-Based Matching of Patients and Targeted Therapies for Precision Oncology, First Author: Qingzhi Liu, Min Jin Ha, Rupam Bhattacharyya, Lana Garmire, Veerabhadran Baladandayuthapani, Year: 2020\n",
      "Title: The Power of Dynamic Social Networks to Predict Individuals' Mental Health, First Author: Shikang Liu, David Hachen, Omar Lizardo, Christian Poellabauer, Aaron Striegel, Tijana Milenkovic, Year: 2020\n",
      "Title: Implementing a Cloud Based Method for Protected Clinical Trial Data Sharing, First Author: Gaurav Luthria, Qingbo Wang, Year: 2020\n",
      "Title: Phenome-wide Association Studies on Cardiovascular Health and Fatty Acids Considering Phenotype Quality Control Practices for Epidemiological Data, First Author: Kristin Passero, Xi He, Jiayan Zhou, Bertram Mueller-Myhsok, Marcus E. Kleber, Winfried Maerz, Molly A. Hall, Year: 2020\n",
      "Title: Pathway and Network Embedding Methods for Prioritizing Psychiatric Drugs, First Author: Yash Pershad, Margaret Guo, Russ B. Altman, Year: 2020\n",
      "Title: aTEMPO: Pathway-Specific Temporal Anomalies for Precision Therapeutics, First Author: Christopher Michael Pietras, Liam Power, Donna K. Slonim, Year: 2020\n",
      "Title: Robust-ODAL: Learning from Heterogeneous Health Systems Without Sharing Patient-Level Data, First Author: Jiayi Tong, Rui Duan, Ruowang Li, Martijn J. Scheuemie, Jason H. Moore, Yong Chen, Year: 2020\n",
      "Title: Feature Selection and Dimension Reduction of Social Autism Data, First Author: Peter Washington, Kelley Marie Paskov, Haik Kalantarian, Nathaniel Stockham, Catalin Voss, Aaron Kline, Ritik Patnaik, Brianna Chrisman, Maya Varma, Qandeel Tariq, Kaitlyn Dunlap, Jessey Schwartz, Nick Haber, Dennis P. Wall, Year: 2020\n",
      "Title: Computationally Efficient, Exact, Covariate-Adjusted Genetic Principal Component Analysis by Leveraging Individual Marker Summary Statistics from Large Biobanks, First Author: Jack Wolf, Martha Barnard, Xueting Xia, Nathan Ryder, Jason Westra, Nathan Tintle, Year: 2020\n"
     ]
    }
   ],
   "source": [
    "paper_meta.update(collect_titles_authors_years(1998, 2024))\n",
    "for title, info in paper_meta.items():\n",
    "    if info[1] == 2020:\n",
    "        print(f\"Title: {title}, First Author: {info[0]}, Year: {info[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08933c",
   "metadata": {},
   "source": [
    "## Get DOIs for as many papers as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9453ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting DOIs:  36%|██████████████████▏                                | 454/1273 [29:24<53:03,  3.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_3701925/1150628649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Getting DOIs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_doi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_doi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mpaper_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     print(f\"DOI: {doi}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ipykernel_3701925/1150628649.py\u001b[0m in \u001b[0;36mget_doi\u001b[0;34m(title, author, year)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"mailto\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sameeksha.garg@dartmouth.edu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mpreload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             )\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2024/user/sgarg/anaconda3/envs/psb_rag/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_doi(title, author, year):\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\n",
    "        \"query.bibliographic\": f\"{title.replace(' ', '+')}+{author.replace(' ', '+')}+{year}\",\n",
    "        \"rows\": 3,\n",
    "        \"mailto\": \"sameeksha.garg@dartmouth.edu\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "def extract_doi(data, year):\n",
    "    # Extract the top two results\n",
    "    items = data['message']['items']\n",
    "    \n",
    "    # Find the DOI that starts with 10.1142\n",
    "    for item in items:\n",
    "        doi = item['DOI']\n",
    "        if doi.startswith('10.1142') and item[\"container-title\"] == [f\"Biocomputing {(int(year))}\"]:\n",
    "            return doi\n",
    "    return None\n",
    "\n",
    "for title, info in tqdm(paper_meta.items(), desc=\"Getting DOIs\"):\n",
    "    doi = extract_doi(get_doi(title, info[0], info[1]), info[1])\n",
    "    paper_meta[title] = (info[0], info[1], doi)\n",
    "#     print(f\"DOI: {doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5086878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for title, details in paper_meta.items():\n",
    "    authors, year = details\n",
    "    data.append({'Title': title, 'Authors': authors, 'Year': year})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa9061",
   "metadata": {},
   "source": [
    "## Get PubMed IDs for all papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da1210",
   "metadata": {},
   "source": [
    "Not all papers have DOIs and this makes querying scopus much easier. Used MetaPub (https://github.com/metapub/metapub) (https://pypi.org/project/metapub/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60caddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import metapub\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NCBI_API_KEY'] = '4216f1a2a91c969d346d66f491930ec94508'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the stop words list\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the function to clean the text\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[-:;()\"\\',]', ' ', text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in stop_words and word != 'abstract']\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pubmed(title, authors, year, detailed=False):\n",
    "    base_url = \"https://pubmed.ncbi.nlm.nih.gov/api/citmatch/\"\n",
    "    if detailed:\n",
    "        params = {\n",
    "            \"method\": \"auto\",\n",
    "            \"raw-text\": f\"{title.replace(' ', '+')}+{authors.replace(' ', '+')}+{year}\",\n",
    "            \"journal\": \"Pac Symp Biocomput\",\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "    else:\n",
    "       params = {\n",
    "            \"method\": \"auto\",\n",
    "            \"raw-text\": title,\n",
    "            \"journal\": \"Pac Symp Biocomput\",\n",
    "            \"retmode\": \"json\"\n",
    "        } \n",
    "            \n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    # Extract PubMed ID from the response\n",
    "    pubmed_ids = data.get('result', {}).get('uids', [])\n",
    "    return pubmed_ids\n",
    "\n",
    "# Clean the titles, query PubMed API, and store PubMed IDs\n",
    "pubmed_results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    title = row['Title']\n",
    "    authors = row['Authors']\n",
    "    year = row['Year']\n",
    "    cleaned_title = clean_text(title)\n",
    "    pubmed_ids = query_pubmed(cleaned_title, authors, year)\n",
    "    if pubmed_ids == []:\n",
    "        pubmed_ids = query_pubmed(cleaned_title, authors, year, True)\n",
    "#         if pubmed_ids == []:\n",
    "#             print(f\"no record found for title: {cleaned_title}\")\n",
    "#             print(f\"{cleaned_title.replace(' ', '+')}+{authors.replace(' ', '+')}+{year}\")\n",
    "#             print(f\"{title.replace(' ', '+')}+{authors.replace(' ', '+')}+{year}\")\n",
    "    pubmed_results.append({'Title': title, \"Authors\": authors, \"Year\": year, \"DOI\": row['DOI'], 'PubMed IDs': pubmed_ids})\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "new_results_df = pd.DataFrame(pubmed_results)\n",
    "\n",
    "# Print the results\n",
    "display(new_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6679ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_data = new_results_df\n",
    "pubmed_data.insert(0, 'Original Title', '')\n",
    "\n",
    "def get_journal_name_and_title(fetch, pubmed_id):\n",
    "    article = fetch.article_by_pmid(pubmed_id)\n",
    "    return (article.journal, article.title)\n",
    "\n",
    "fetch = metapub.PubMedFetcher()\n",
    "# Iterate through each row and check the PubMed IDs\n",
    "for index, row in tqdm(pubmed_data.iterrows()):\n",
    "    orig_title = row['Title']\n",
    "    pubmed_ids = [item['pubmed'] for item in row['PubMed IDs']]\n",
    "    for pubmed_id in pubmed_ids:\n",
    "        journal_name, title = get_journal_name_and_title(fetch, pubmed_id)\n",
    "        if journal_name == 'Pac Symp Biocomput':\n",
    "            correct_pubmed_id = pubmed_id\n",
    "            break\n",
    "        # Be polite and avoid hitting the server too hard\n",
    "        sleep(0.5)\n",
    "    if correct_pubmed_id:\n",
    "        pubmed_data.at[index, 'PubMed IDs'] = correct_pubmed_id\n",
    "        pubmed_data.at[index, 'Title'] = title\n",
    "        pubmed_data.at[index, 'Original Title'] = orig_title\n",
    "    else:\n",
    "        \"no correct id found\"\n",
    "        \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pubmed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092a854",
   "metadata": {},
   "source": [
    "## Get Scopus IDs and Citation Data for each author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc34a8",
   "metadata": {},
   "source": [
    "In scraping author names from the proceedings webpages, there were many unicode errors and formatting differences (suchas as using initials vs full names from year to year). When creating a co-authorship network, this would lead to ambiguity when determining which authors contributed to multiple papers. To disambiguate the data, queried the Scopus API using pybliometrics, an API wrapper for Scopus (https://pybliometrics.readthedocs.io/en/stable/index.html). For each paper, mapped the authors to their respective Scopus IDs, a unique identifier assigned to each author by Scopus. Used Scopus ID instead of ORCID IDs as not every author necessarily has an ORCID ID, but Scopus automatically assigns each author in its database an ID.\n",
    "\n",
    "For citation network purposes, also got Scopus's citation counts for each paper (regarded as accurate by the academic community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "from pybliometrics.scopus import AuthorRetrieval\n",
    "from pybliometrics.scopus.exception import Scopus404Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0feee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pybliometrics.scopus.init() #includes Elsevier API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pubmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_scopus_authors_cited(pmid):\n",
    "    full_auth = {}\n",
    "    ab = AbstractRetrieval(pmid)\n",
    "    for author in ab.authors:\n",
    "        id = author.auid\n",
    "        au = AuthorRetrieval(id)\n",
    "        full_auth[id] = f\"{au.given_name} {au.surname}\"\n",
    "    return (full_auth, ab.citedby_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Full Authors'] = None\n",
    "df['Cited By Count'] = None\n",
    "\n",
    "default = \"pmid\"\n",
    "# Iterate through each PubMed ID and query Scopus\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    pmid = row['PubMed IDs']\n",
    "    doi = row['DOI']\n",
    "    if default == \"pmid\":\n",
    "        try:\n",
    "            (full_authors, cited_by_count) = query_scopus_authors_cited(pmid)\n",
    "        except Scopus404Error:\n",
    "            print(f\"Scopus404Error for PMID: {pmid}. Trying alternative method...\")\n",
    "            default = \"doi\"\n",
    "            (full_authors, cited_by_count) = query_scopus_authors_cited(doi)\n",
    "    else:\n",
    "        (full_authors, cited_by_count) = query_scopus_authors_cited(doi)\n",
    "    df.at[index, 'Full Authors'] = full_authors\n",
    "    df.at[index, 'Cited By Count'] = cited_by_count\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ed162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('full_author_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fbb04",
   "metadata": {},
   "source": [
    "## Mapping Topic Results from LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b50890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pdf</th>\n",
       "      <th>authors</th>\n",
       "      <th>titles</th>\n",
       "      <th>number</th>\n",
       "      <th>available</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>R.A. Goldstein and R.B. Altman</td>\n",
       "      <td>The Evolution of Biomolecular Structures and t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1996\\0_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>A. Keith Dunker and Richard H. Lathrop</td>\n",
       "      <td>Discovering, Learning, Analyzing and Predictin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1996\\1_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Kiyoshi Asai, Tom Head, Katsumi Nitta and Taka...</td>\n",
       "      <td>Stochastic Models, Formal Systems and Algorith...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1996\\2_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Chris Henn and Michael Teschner</td>\n",
       "      <td>Interactive Molecular Visualization.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1996\\3_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Steven M. Thompson, Susan J. Johns and A. Keit...</td>\n",
       "      <td>Educational Issues in Biocomputing.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1996\\4_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>42</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Michelle Holko, Nick Weber, Chris Lunt, Steven...</td>\n",
       "      <td>Biomedical research in the Cloud: Options and ...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2023\\42_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>43</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Anurag Verma, Jennifer Huffman, Ali Torkmani, ...</td>\n",
       "      <td>High-Performance Computing Meets High-Performa...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2023\\43_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>44</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Ruowang Li, Rui Duan, Lifang He, Jason H. Moore</td>\n",
       "      <td>Risk prediction: Methods, Challenges, and Oppo...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2023\\44_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>45</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Andrew Gentles, Ajit Nirmal, Laura Heiser, Emm...</td>\n",
       "      <td>Single Cell Spatial Biology for Precision Canc...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2023\\45_main_body.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>46</td>\n",
       "      <td>https://psb.stanford.edu/psb-online/proceeding...</td>\n",
       "      <td>Peter Kochunov, Yizhou Ma, Kathryn S. Hatch, S...</td>\n",
       "      <td>Separating Clinical and Subclinical Depression...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2023\\46_main_body.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1373 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                pdf  \\\n",
       "0              0  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "1              1  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "2              2  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "3              3  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "4              4  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "...          ...                                                ...   \n",
       "1368          42  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "1369          43  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "1370          44  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "1371          45  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "1372          46  https://psb.stanford.edu/psb-online/proceeding...   \n",
       "\n",
       "                                                authors  \\\n",
       "0                        R.A. Goldstein and R.B. Altman   \n",
       "1                A. Keith Dunker and Richard H. Lathrop   \n",
       "2     Kiyoshi Asai, Tom Head, Katsumi Nitta and Taka...   \n",
       "3                       Chris Henn and Michael Teschner   \n",
       "4     Steven M. Thompson, Susan J. Johns and A. Keit...   \n",
       "...                                                 ...   \n",
       "1368  Michelle Holko, Nick Weber, Chris Lunt, Steven...   \n",
       "1369  Anurag Verma, Jennifer Huffman, Ali Torkmani, ...   \n",
       "1370    Ruowang Li, Rui Duan, Lifang He, Jason H. Moore   \n",
       "1371  Andrew Gentles, Ajit Nirmal, Laura Heiser, Emm...   \n",
       "1372  Peter Kochunov, Yizhou Ma, Kathryn S. Hatch, S...   \n",
       "\n",
       "                                                 titles  number  available  \\\n",
       "0     The Evolution of Biomolecular Structures and t...     0.0       True   \n",
       "1     Discovering, Learning, Analyzing and Predictin...     1.0       True   \n",
       "2     Stochastic Models, Formal Systems and Algorith...     2.0       True   \n",
       "3                  Interactive Molecular Visualization.     3.0       True   \n",
       "4                   Educational Issues in Biocomputing.     4.0       True   \n",
       "...                                                 ...     ...        ...   \n",
       "1368  Biomedical research in the Cloud: Options and ...    42.0       True   \n",
       "1369  High-Performance Computing Meets High-Performa...    43.0       True   \n",
       "1370  Risk prediction: Methods, Challenges, and Oppo...    44.0       True   \n",
       "1371  Single Cell Spatial Biology for Precision Canc...    45.0       True   \n",
       "1372  Separating Clinical and Subclinical Depression...    46.0       True   \n",
       "\n",
       "                   filename  \n",
       "0      1996\\0_main_body.txt  \n",
       "1      1996\\1_main_body.txt  \n",
       "2      1996\\2_main_body.txt  \n",
       "3      1996\\3_main_body.txt  \n",
       "4      1996\\4_main_body.txt  \n",
       "...                     ...  \n",
       "1368  2023\\42_main_body.txt  \n",
       "1369  2023\\43_main_body.txt  \n",
       "1370  2023\\44_main_body.txt  \n",
       "1371  2023\\45_main_body.txt  \n",
       "1372  2023\\46_main_body.txt  \n",
       "\n",
       "[1373 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def concatenate_csv_files(folder_path, output_file):\n",
    "    # List to hold all dataframes\n",
    "    all_dataframes = []\n",
    "    # Iterate over all CSV files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract the year from the filename\n",
    "            year = filename.split('.')[0]\n",
    "            \n",
    "            # Add the new column for filenames formatted as YYYY/NN_main_body.txt\n",
    "            df['filename'] = df.apply(lambda row: f\"{year}\\\\{int(row['Unnamed: 0'])}_main_body.txt\", axis=1)\n",
    "            \n",
    "            # Append the dataframe to the list\n",
    "            all_dataframes.append(df)\n",
    "    # Concatenate all dataframes\n",
    "    final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the combined dataframe to a new CSV file\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Define the folder path and output file path\n",
    "folder_path = 'Paper_CSV'\n",
    "output_file = 'Titles_and_Filenames.csv'\n",
    "\n",
    "# Call the function\n",
    "combined_df = concatenate_csv_files(folder_path, output_file)\n",
    "\n",
    "# Display the final dataframe\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c0d5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics_documents = pd.read_csv('LDA_topics_documents.csv')\n",
    "combined_topic_data = pd.read_csv('Titles_and_Filenames.csv')\n",
    "full_author_results = pd.read_csv('full_author_results.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Merge LDA_topics_documents with combined_topic_data based on document and filename\n",
    "merged_lda = pd.merge(lda_topics_documents, combined_topic_data, left_on='document', right_on='filename', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da09e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Title</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>DOI</th>\n",
       "      <th>PubMed IDs</th>\n",
       "      <th>Full Authors</th>\n",
       "      <th>distr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Protein structure comparison using representat...</td>\n",
       "      <td>Protein structure comparison using representat...</td>\n",
       "      <td>Tatsuya Akutsu and Hiroshi Tashimo</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9390221</td>\n",
       "      <td>{7102080520: 'Tatsuya Akutsu', 7801453395: 'H....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quaternion Contact Ribbons: a New Tool for Vis...</td>\n",
       "      <td>Quaternion contact ribbons: a new tool for vis...</td>\n",
       "      <td>Kurt Albrect, John Hart, Alex Shaw and A. Keit...</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9390222</td>\n",
       "      <td>{7103391181: 'K. Albrecht', 55243117900: 'John...</td>\n",
       "      <td>[5.2092910e-01 3.2582842e-02 3.0846679e-01 7.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Protein Fold Recognition via Sequence to ...</td>\n",
       "      <td>Fast protein fold recognition via sequence to ...</td>\n",
       "      <td>Nickolai N. Alexandrov, Ruth Nussinov and Ralk...</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9390223</td>\n",
       "      <td>{7004299612: 'Nickolai N. Alexandrov', 3457217...</td>\n",
       "      <td>[0.35456887 0.0006435  0.12934364 0.0006435  0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Programming Course in Bioinformatics for Com...</td>\n",
       "      <td>A programming course in bioinformatics for com...</td>\n",
       "      <td>Russ B. Altman and John Koza</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9390224</td>\n",
       "      <td>{7202798518: 'Russ B. Altman', 55167951500: 'J...</td>\n",
       "      <td>[1.6253847e-01 2.6070837e-02 5.2382267e-01 3.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Massively Parallel Simulated Annealing Algorit...</td>\n",
       "      <td>Massively parallel algorithms for chromosome r...</td>\n",
       "      <td>Suchendra M. Bhandarkar, Sridhar Chirravuri, J...</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9390225</td>\n",
       "      <td>{7006828161: 'Suchendra M. Bhandarkar', 650830...</td>\n",
       "      <td>[9.5343450e-03 1.9284661e-01 7.2745472e-02 6.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Deconvolution of Nascent Sequencing Data Using...</td>\n",
       "      <td>Deconvolution of Nascent Sequencing Data Using...</td>\n",
       "      <td>Zachary Maas, Rutendo Sigauke, Robin Dowelli</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.1142/9789811286421_0043</td>\n",
       "      <td>38160307</td>\n",
       "      <td>{57216789177: 'Zachary L. Maas', 57200620038: ...</td>\n",
       "      <td>[0.00071785 0.09369659 0.04105422 0.04378889 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Splitpea: Quantifying Protein Interaction Netw...</td>\n",
       "      <td>Splitpea: quantifying protein interaction netw...</td>\n",
       "      <td>Ruth Dannenfelser, Vicky Yao</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.1142/9789811286421_0044</td>\n",
       "      <td>38160308</td>\n",
       "      <td>{36145038300: 'Ruth Dannenfelser', 54381136200...</td>\n",
       "      <td>[4.4734727e-05 1.1675763e-02 2.1070056e-02 4.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Lymphocyte Count Derived Polygenic Score and I...</td>\n",
       "      <td>Lymphocyte Count Derived Polygenic Score and I...</td>\n",
       "      <td>Kathleen M. Cardone, Scott Dudek, Karl Keat, Y...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.1142/9789811286421_0045</td>\n",
       "      <td>38160309</td>\n",
       "      <td>{57945000000: 'Kathleen M. Cardone', 700679054...</td>\n",
       "      <td>[5.0705270e-04 2.8118375e-03 4.6095698e-05 2.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Polygenic Risk Scores for Cardiometabolic Trai...</td>\n",
       "      <td>Polygenic risk scores for cardiometabolic trai...</td>\n",
       "      <td>Rachel Kember, Shefali Verma, Anurag Verma, Br...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.1142/9789811286421_0046</td>\n",
       "      <td>38160310</td>\n",
       "      <td>{35722432500: 'Rachel L. Kember', 56386609500:...</td>\n",
       "      <td>[4.1469688e-05 3.3590449e-03 1.5385253e-02 5.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>intCC: An Efficient Weighted Integrative Conse...</td>\n",
       "      <td>intCC: An efficient weighted integrative conse...</td>\n",
       "      <td>Can Huang, Pei Fen Kuan</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.1142/9789811286421_0047</td>\n",
       "      <td>38160311</td>\n",
       "      <td>{58795878000: 'Can Huang', 23492588300: 'Pei F...</td>\n",
       "      <td>[4.2874293e-05 2.1865889e-03 5.1877899e-03 2.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1276 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Original Title  \\\n",
       "0     Protein structure comparison using representat...   \n",
       "1     Quaternion Contact Ribbons: a New Tool for Vis...   \n",
       "2     Fast Protein Fold Recognition via Sequence to ...   \n",
       "3     A Programming Course in Bioinformatics for Com...   \n",
       "4     Massively Parallel Simulated Annealing Algorit...   \n",
       "...                                                 ...   \n",
       "1271  Deconvolution of Nascent Sequencing Data Using...   \n",
       "1272  Splitpea: Quantifying Protein Interaction Netw...   \n",
       "1273  Lymphocyte Count Derived Polygenic Score and I...   \n",
       "1274  Polygenic Risk Scores for Cardiometabolic Trai...   \n",
       "1275  intCC: An Efficient Weighted Integrative Conse...   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     Protein structure comparison using representat...   \n",
       "1     Quaternion contact ribbons: a new tool for vis...   \n",
       "2     Fast protein fold recognition via sequence to ...   \n",
       "3     A programming course in bioinformatics for com...   \n",
       "4     Massively parallel algorithms for chromosome r...   \n",
       "...                                                 ...   \n",
       "1271  Deconvolution of Nascent Sequencing Data Using...   \n",
       "1272  Splitpea: quantifying protein interaction netw...   \n",
       "1273  Lymphocyte Count Derived Polygenic Score and I...   \n",
       "1274  Polygenic risk scores for cardiometabolic trai...   \n",
       "1275  intCC: An efficient weighted integrative conse...   \n",
       "\n",
       "                                                Authors  Year  \\\n",
       "0                    Tatsuya Akutsu and Hiroshi Tashimo  1996   \n",
       "1     Kurt Albrect, John Hart, Alex Shaw and A. Keit...  1996   \n",
       "2     Nickolai N. Alexandrov, Ruth Nussinov and Ralk...  1996   \n",
       "3                          Russ B. Altman and John Koza  1996   \n",
       "4     Suchendra M. Bhandarkar, Sridhar Chirravuri, J...  1996   \n",
       "...                                                 ...   ...   \n",
       "1271       Zachary Maas, Rutendo Sigauke, Robin Dowelli  2024   \n",
       "1272                       Ruth Dannenfelser, Vicky Yao  2024   \n",
       "1273  Kathleen M. Cardone, Scott Dudek, Karl Keat, Y...  2024   \n",
       "1274  Rachel Kember, Shefali Verma, Anurag Verma, Br...  2024   \n",
       "1275                            Can Huang, Pei Fen Kuan  2024   \n",
       "\n",
       "                             DOI  PubMed IDs  \\\n",
       "0                            NaN     9390221   \n",
       "1                            NaN     9390222   \n",
       "2                            NaN     9390223   \n",
       "3                            NaN     9390224   \n",
       "4                            NaN     9390225   \n",
       "...                          ...         ...   \n",
       "1271  10.1142/9789811286421_0043    38160307   \n",
       "1272  10.1142/9789811286421_0044    38160308   \n",
       "1273  10.1142/9789811286421_0045    38160309   \n",
       "1274  10.1142/9789811286421_0046    38160310   \n",
       "1275  10.1142/9789811286421_0047    38160311   \n",
       "\n",
       "                                           Full Authors  \\\n",
       "0     {7102080520: 'Tatsuya Akutsu', 7801453395: 'H....   \n",
       "1     {7103391181: 'K. Albrecht', 55243117900: 'John...   \n",
       "2     {7004299612: 'Nickolai N. Alexandrov', 3457217...   \n",
       "3     {7202798518: 'Russ B. Altman', 55167951500: 'J...   \n",
       "4     {7006828161: 'Suchendra M. Bhandarkar', 650830...   \n",
       "...                                                 ...   \n",
       "1271  {57216789177: 'Zachary L. Maas', 57200620038: ...   \n",
       "1272  {36145038300: 'Ruth Dannenfelser', 54381136200...   \n",
       "1273  {57945000000: 'Kathleen M. Cardone', 700679054...   \n",
       "1274  {35722432500: 'Rachel L. Kember', 56386609500:...   \n",
       "1275  {58795878000: 'Can Huang', 23492588300: 'Pei F...   \n",
       "\n",
       "                                                  distr  \n",
       "0                                                   NaN  \n",
       "1     [5.2092910e-01 3.2582842e-02 3.0846679e-01 7.9...  \n",
       "2     [0.35456887 0.0006435  0.12934364 0.0006435  0...  \n",
       "3     [1.6253847e-01 2.6070837e-02 5.2382267e-01 3.9...  \n",
       "4     [9.5343450e-03 1.9284661e-01 7.2745472e-02 6.3...  \n",
       "...                                                 ...  \n",
       "1271  [0.00071785 0.09369659 0.04105422 0.04378889 0...  \n",
       "1272  [4.4734727e-05 1.1675763e-02 2.1070056e-02 4.0...  \n",
       "1273  [5.0705270e-04 2.8118375e-03 4.6095698e-05 2.5...  \n",
       "1274  [4.1469688e-05 3.3590449e-03 1.5385253e-02 5.0...  \n",
       "1275  [4.2874293e-05 2.1865889e-03 5.1877899e-03 2.4...  \n",
       "\n",
       "[1276 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_topic_data.rename(columns={'titles': 'Original Title'}, inplace=True)\n",
    "merged_data = pd.merge(full_author_results, combined_topic_data, on='Original Title', how='left')\n",
    "\n",
    "augmented_data = pd.merge(merged_data, lda_topics_documents, left_on='filename', right_on='document', how='left')\n",
    "\n",
    "topic_distributions = augmented_data[['Original Title', 'distr']]\n",
    "\n",
    "# Merge this new dataframe back with full_author_results to preserve all rows\n",
    "final_full_author_results = pd.merge(full_author_results, topic_distributions, on='Original Title', how='left')\n",
    "\n",
    "display(final_full_author_results)\n",
    "\n",
    "# final_full_author_results.to_csv('PSB_Paper_Data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f930f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psb_rag",
   "language": "python",
   "name": "psb_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
