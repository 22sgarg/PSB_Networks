{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3598e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada093bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_topic_distribution(author_papers):\n",
    "    if not author_papers:\n",
    "        return np.zeros(len(author_papers[0]))\n",
    "    return np.mean(author_papers, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fbc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_list(s, num_topics=14):\n",
    "    try:\n",
    "#         print(s)\n",
    "        return np.fromstring(s.strip('[]'), sep=' ')\n",
    "    except:\n",
    "        return np.zeros(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be426dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Full_Author_Topic_w_2002.csv'\n",
    "output_folder = 'coauthorship_networks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1c52e",
   "metadata": {},
   "source": [
    "Cumulative Networks and Leiden Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95915521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cumulative_coauthorship_networks(file_path, output_folder):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "#     data['Full Authors'] = data['Full Authors']\n",
    "#     data['distr'] = data['distr'].apply(lambda x: parse_string_to_list(x))\n",
    "    \n",
    "#     print(data)\n",
    "    # Initialize a dictionary to hold cumulative graphs for each year\n",
    "    cumulative_graphs = {}\n",
    "    author_topic_distributions = {}\n",
    "\n",
    "    # Create the output folder if it does not exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Create coauthorship networks\n",
    "    for year in sorted(df['Year'].unique()):\n",
    "        print(year)\n",
    "#         print(df)\n",
    "#         print(df.columns)\n",
    "#         print(df['Year'])\n",
    "        yearly_data = df[df['Year'] <= year]\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        \n",
    "        for _, row in yearly_data.iterrows():\n",
    "            authors_dict = eval(row['Full Authors'])\n",
    "            topic_distribution = parse_string_to_list(row['distr'])\n",
    "#             print(topic_distribution)\n",
    "            for author_id, author_name in authors_dict.items():\n",
    "                if author_id not in author_topic_distributions:\n",
    "                    author_topic_distributions[author_id] = []\n",
    "                author_topic_distributions[author_id].append(topic_distribution)\n",
    "                if author_id not in G:\n",
    "                    G.add_node(author_id, name=author_name)\n",
    "\n",
    "            author_ids = list(authors_dict.keys())\n",
    "            for i, author_id in enumerate(author_ids):\n",
    "                for coauthor_id in author_ids[i+1:]:\n",
    "                    if G.has_edge(author_id, coauthor_id):\n",
    "                        G[author_id][coauthor_id]['weight'] += 1\n",
    "                    else:\n",
    "                        G.add_edge(author_id, coauthor_id, weight=1)\n",
    "\n",
    "        # Calculate average topic distributions for authors\n",
    "        avg_topic_distributions = {author_id: calculate_average_topic_distribution(papers)\n",
    "                                   for author_id, papers in author_topic_distributions.items()}\n",
    "\n",
    "        # Store average topic distributions as node attributes\n",
    "        for author_id, avg_distribution in avg_topic_distributions.items():\n",
    "            if author_id in G:\n",
    "                G.nodes[author_id]['avg_topic_distribution'] = avg_distribution.tolist()\n",
    "\n",
    "        # Calculate author alignment (topic similarity) for each edge\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            if u in avg_topic_distributions and v in avg_topic_distributions:\n",
    "                similarity = cosine_similarity([avg_topic_distributions[u]], [avg_topic_distributions[v]])[0][0]\n",
    "                G[u][v]['alignment'] = similarity\n",
    "\n",
    "        cumulative_graphs[year] = G\n",
    "        \n",
    "    return cumulative_graphs\n",
    "    \n",
    "#     print(f\"Average topic distributions for year {year}: {avg_topic_distributions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbbc2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "cumul_graphs = create_cumulative_coauthorship_networks(file_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec42c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, graph in cumul_graphs.items():\n",
    "    nx.write_gml(graph, os.path.join(output_folder, f\"cumulative_coauthorship_network_{year}.gml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167cd1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "for year, graph in cumul_graphs.items():\n",
    "        ig_graph = ig.Graph.from_networkx(graph)\n",
    "\n",
    "#         ig_graph = ig.Graph.TupleList(graph.edges(), directed=False)\n",
    "#         weights = [graph[u][v]['weight'] for u, v in graph.edges()]\n",
    "#         ig_graph.es['weight'] = weights\n",
    "        \n",
    "        # Run Leiden clustering\n",
    "        partition = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition)\n",
    "\n",
    "        # Save clustering results\n",
    "        clusters = {vertex['name']: cluster for vertex, cluster in zip(ig_graph.vs, partition.membership)}\n",
    "        with open(os.path.join(output_folder, f\"leiden_clustering_cumulative_{year}.json\"), 'w') as f:\n",
    "            json.dump(clusters, f)\n",
    "        \n",
    "        print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694dc09",
   "metadata": {},
   "source": [
    "Cross-Sectional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc1f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cs_coauthorship_networks(file_path, output_folder):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "#     data['Full Authors'] = data['Full Authors']\n",
    "#     data['distr'] = data['distr'].apply(lambda x: parse_string_to_list(x))\n",
    "    \n",
    "#     print(data)\n",
    "    # Initialize a dictionary to hold cumulative graphs for each year\n",
    "\n",
    "    cross_sectional_graphs = {}\n",
    "\n",
    "    # Create the output folder if it does not exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Create coauthorship networks\n",
    "    for year in sorted(df['Year'].unique()):\n",
    "        print(year)\n",
    "        yearly_data = df[df['Year'] == year]\n",
    "        \n",
    "        author_topic_distributions = {}\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        for _, row in yearly_data.iterrows():\n",
    "            authors_dict = eval(row['Full Authors'])\n",
    "            topic_distribution = parse_string_to_list(row['distr'])\n",
    "            for author_id, author_name in authors_dict.items():\n",
    "                if author_id not in author_topic_distributions:\n",
    "                    author_topic_distributions[author_id] = []\n",
    "                author_topic_distributions[author_id].append(topic_distribution)\n",
    "                if author_id not in G:\n",
    "                    G.add_node(author_id, name=author_name)\n",
    "\n",
    "            author_ids = list(authors_dict.keys())\n",
    "            for i, author_id in enumerate(author_ids):\n",
    "                for coauthor_id in author_ids[i+1:]:\n",
    "                    G.add_edge(author_id, coauthor_id)\n",
    "\n",
    "        # Calculate average topic distributions for authors\n",
    "        avg_topic_distributions = {author_id: calculate_average_topic_distribution(papers)\n",
    "                                   for author_id, papers in author_topic_distributions.items()}\n",
    "\n",
    "        # Store average topic distributions as node attributes\n",
    "        for author_id, avg_distribution in avg_topic_distributions.items():\n",
    "            if author_id in G:\n",
    "                G.nodes[author_id]['avg_topic_distribution'] = avg_distribution.tolist()\n",
    "\n",
    "        # Calculate author alignment (topic similarity) for each edge\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            if u in avg_topic_distributions and v in avg_topic_distributions:\n",
    "                similarity = cosine_similarity([avg_topic_distributions[u]], [avg_topic_distributions[v]])[0][0]\n",
    "                G[u][v]['alignment'] = similarity\n",
    "\n",
    "        cross_sectional_graphs[year] = G\n",
    "        \n",
    "    return cross_sectional_graphs\n",
    "    \n",
    "#     print(f\"Average topic distributions for year {year}: {avg_topic_distributions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c690b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "cs_graphs = create_cs_coauthorship_networks(file_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2444df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1996: <networkx.classes.graph.Graph object at 0x154f4a47a410>, 1997: <networkx.classes.graph.Graph object at 0x154f4a489410>, 1998: <networkx.classes.graph.Graph object at 0x154f512e1e10>, 1999: <networkx.classes.graph.Graph object at 0x154f4b440a10>, 2000: <networkx.classes.graph.Graph object at 0x154f512e1d10>, 2001: <networkx.classes.graph.Graph object at 0x154f4bbb4610>, 2002: <networkx.classes.graph.Graph object at 0x154f4bc07610>, 2003: <networkx.classes.graph.Graph object at 0x154f4bbb4410>, 2004: <networkx.classes.graph.Graph object at 0x154f49fc60d0>, 2005: <networkx.classes.graph.Graph object at 0x154f49f80b50>, 2006: <networkx.classes.graph.Graph object at 0x154f49edb1d0>, 2007: <networkx.classes.graph.Graph object at 0x154f49f80c90>, 2008: <networkx.classes.graph.Graph object at 0x154f4bbb4910>, 2009: <networkx.classes.graph.Graph object at 0x154f49e39a10>, 2010: <networkx.classes.graph.Graph object at 0x154f49d9f3d0>, 2011: <networkx.classes.graph.Graph object at 0x154f49fc6190>, 2012: <networkx.classes.graph.Graph object at 0x154f49d2eb10>, 2013: <networkx.classes.graph.Graph object at 0x154f49ce0ed0>, 2014: <networkx.classes.graph.Graph object at 0x154f49cb7210>, 2015: <networkx.classes.graph.Graph object at 0x154f49c7f410>, 2016: <networkx.classes.graph.Graph object at 0x154f49c7f650>, 2017: <networkx.classes.graph.Graph object at 0x154f49bce790>, 2018: <networkx.classes.graph.Graph object at 0x154f49b42ad0>, 2019: <networkx.classes.graph.Graph object at 0x154f49c7f690>, 2020: <networkx.classes.graph.Graph object at 0x154f49a43290>, 2021: <networkx.classes.graph.Graph object at 0x154f499c11d0>, 2022: <networkx.classes.graph.Graph object at 0x154f499c1190>, 2023: <networkx.classes.graph.Graph object at 0x154f4995a950>, 2024: <networkx.classes.graph.Graph object at 0x154f498be290>}\n"
     ]
    }
   ],
   "source": [
    "print(cs_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a67041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, graph in cs_graphs.items():\n",
    "    nx.write_gml(graph, os.path.join(output_folder, f\"cross_sectional_coauthorship_network_{year}.gml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e55c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "for year, graph in cs_graphs.items():\n",
    "        ig_graph = ig.Graph.from_networkx(graph)\n",
    "\n",
    "#         ig_graph = ig.Graph.TupleList(graph.edges(), directed=False)\n",
    "#         weights = [graph[u][v]['weight'] for u, v in graph.edges()]\n",
    "#         ig_graph.es['weight'] = weights\n",
    "        \n",
    "        # Run Leiden clustering\n",
    "        partition = leidenalg.find_partition(ig_graph, leidenalg.ModularityVertexPartition)\n",
    "\n",
    "        # Save clustering results\n",
    "        clusters = {vertex['name']: cluster for vertex, cluster in zip(ig_graph.vs, partition.membership)}\n",
    "        with open(os.path.join(output_folder, f\"leiden_clustering_cross_sect_{year}.json\"), 'w') as f:\n",
    "            json.dump(clusters, f)\n",
    "        \n",
    "        print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279170c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psb_rag",
   "language": "python",
   "name": "psb_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
